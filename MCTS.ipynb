{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search on Chess Game\n",
    "In this notebook we demonstrate the Monte Carlo tree search applied to our chess implementation.\n",
    "More specifically, starting from the initial game situation, we learn the best moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess import GameController, GameControllerAdapter, MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_info(node):\n",
    "    result = \"\" \n",
    "    result += f\"{node.wins}/{node.simulations} (Wins/Simulations)\\n\"\n",
    "    win_rate = node.wins/node.simulations if node.simulations != 0 else None\n",
    "    result += f\"{win_rate} (Wins/Simulations) \\n\"\n",
    "    result += node.status()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl = GameController()\n",
    "adapter = GameControllerAdapter(ctl)\n",
    "mcts = MCTS(adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 simulations run.\n",
      "100 simulations run.\n",
      "200 simulations run.\n",
      "300 simulations run.\n",
      "400 simulations run.\n",
      "500 simulations run.\n",
      "600 simulations run.\n",
      "700 simulations run.\n",
      "800 simulations run.\n",
      "900 simulations run.\n"
     ]
    }
   ],
   "source": [
    "mcts.run(n_simulations=1000, verbose=True, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best first move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root node wins/simulations: Node level: 0\n",
      "Wins: 505/1000\n",
      "Number of possible first moves: 26\n",
      "Ranking of moves:\n",
      "43/67 (Wins/Simulations)\n",
      "0.6417910447761194 (Wins/Simulations) \n",
      " x . . . . . . o\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . x\n",
      "Active Player: black\n",
      "Winner: None\n",
      "39/62 (Wins/Simulations)\n",
      "0.6290322580645161 (Wins/Simulations) \n",
      " o . . . . . . x\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " x . . . . . . .\n",
      "Active Player: black\n",
      "Winner: None\n",
      "30/52 (Wins/Simulations)\n",
      "0.5769230769230769 (Wins/Simulations) \n",
      " o . . . . . . o\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . x . . . x\n",
      "Active Player: black\n",
      "Winner: None\n",
      "29/51 (Wins/Simulations)\n",
      "0.5686274509803921 (Wins/Simulations) \n",
      " o . . . . . . o\n",
      " x . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . x\n",
      "Active Player: black\n",
      "Winner: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Root node wins/simulations: {mcts.node}\")\n",
    "print(f\"Number of possible first moves: {len(mcts.node.children)}\")\n",
    "print(\"Best moves:\")\n",
    "for c in mcts.best_moves()[:4]:\n",
    "    print(node_info(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts.node = mcts.node.rank_child_nodes()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 simulations run.\n",
      "50 simulations run.\n",
      "100 simulations run.\n",
      "150 simulations run.\n",
      "200 simulations run.\n",
      "250 simulations run.\n",
      "300 simulations run.\n",
      "350 simulations run.\n",
      "400 simulations run.\n",
      "450 simulations run.\n",
      "500 simulations run.\n",
      "550 simulations run.\n",
      "600 simulations run.\n",
      "650 simulations run.\n",
      "700 simulations run.\n",
      "750 simulations run.\n",
      "800 simulations run.\n",
      "850 simulations run.\n",
      "900 simulations run.\n",
      "950 simulations run.\n"
     ]
    }
   ],
   "source": [
    "mcts.run(n_simulations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best move sequence learned from the initial game.\n",
    "Thinking about the best initial move, MCTS also learns something about subsequent moves, alternating between best moves for the white and the black player. We see, however, that the depth and simulation number here is still limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/67 (Wins/Simulations)\n",
      "0.6417910447761194 (Wins/Simulations) \n",
      " x . . . . . . o\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . x\n",
      "Active Player: black\n",
      "Winner: None\n",
      "6/9 (Wins/Simulations)\n",
      "0.6666666666666666 (Wins/Simulations) \n",
      " x . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . o\n",
      " . . . . . . . x\n",
      "Active Player: white\n",
      "Winner: None\n",
      "1/1 (Wins/Simulations)\n",
      "1.0 (Wins/Simulations) \n",
      " x . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . o\n",
      " . . . . . x . .\n",
      "Active Player: black\n",
      "Winner: None\n",
      "0/1 (Wins/Simulations)\n",
      "0.0 (Wins/Simulations) \n",
      " x . . . . . . .\n",
      " . . . . . . . o\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . x . .\n",
      "Active Player: white\n",
      "Winner: None\n"
     ]
    }
   ],
   "source": [
    "# Play the best \"game\" learned so far (not necessarily up to a final game state).\n",
    "node = mcts.node\n",
    "while node.has_children():\n",
    "    node = node.rank_child_nodes()[0]\n",
    "    print(node_info(node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play a full game.\n",
    "Here we simulate a full game played through MCTS against itself. Starting from each chosen state, MCTS is retrained to select the subsequent best move, hence alternating between the white and the black player. Some observations we made here:\n",
    "- Starting the game with only two towers per player, it never ends. This is expected unless the AI makes a mistake.\n",
    "- Starting with the complete set of chess pieces per player, we see moves, that are much human-like (e.g., moving pieces somewhere were they cover a large area).\n",
    "- However, some very obvious moves are not done by the AI. It seems that altogether the policy of selecting totally random moves in a playout (i.e., a simulation) is insufficient for determining the value of a game situation.\n",
    "- For the same reason, the AI exhibits some risky, greedy behavior, e.g., moving to positions where it is closer to the opponent's king while ignoring that own pieces are under attack.\n",
    "- Often, the value of beating an enemy piece that is not the king seems to be underestimated. The reason might be that there occurs too much randomness on the way down the (relatively deep) game tree. The behavior here might be too unrealistic and the number of possible moves to large.\n",
    "- A larger number of simulations might be required (here we used 1000 per move)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/86 (Wins/Simulations)\n",
      "0.6395348837209303 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜\n",
      " ♟ ♟ ♟ ♟ ♟ ♟ ♟ ♟\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . . . . . . .\n",
      " . . ♘ . . . . .\n",
      " ♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "52/89 (Wins/Simulations)\n",
      "0.5842696629213483 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜\n",
      " ♟ ♟ ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . . .\n",
      " . . . . ♟ . . .\n",
      " . . . . . . . .\n",
      " . . ♘ . . . . .\n",
      " ♙ ♙ ♙ ♙ ♙ ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "49/81 (Wins/Simulations)\n",
      "0.6049382716049383 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ ♞ ♜\n",
      " ♟ ♟ ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . . .\n",
      " . . . . ♟ . . .\n",
      " . . . . . . . .\n",
      " . . ♘ . ♙ . . .\n",
      " ♙ ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "32/54 (Wins/Simulations)\n",
      "0.5925925925925926 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ ♟ ♟ ♟ ♞ ♟ ♟ ♟\n",
      " . . . . . . . .\n",
      " . . . . ♟ . . .\n",
      " . . . . . . . .\n",
      " . . ♘ . ♙ . . .\n",
      " ♙ ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "25/43 (Wins/Simulations)\n",
      "0.5813953488372093 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ ♟ ♟ ♟ ♞ ♟ ♟ ♟\n",
      " . . . . . . . .\n",
      " . . . . ♟ . . .\n",
      " ♙ . . . . . . .\n",
      " . . ♘ . ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "58/91 (Wins/Simulations)\n",
      "0.6373626373626373 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ ♟ ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . . . . ♟ . . .\n",
      " ♙ . . . . . . .\n",
      " . . ♘ . ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ ♗ ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "36/56 (Wins/Simulations)\n",
      "0.6428571428571429 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ ♟ ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . . . . ♟ . . .\n",
      " ♙ . . . . . . .\n",
      " . . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "43/70 (Wins/Simulations)\n",
      "0.6142857142857143 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♙ . . . . . . .\n",
      " . . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " ♖ . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "34/52 (Wins/Simulations)\n",
      "0.6538461538461539 (Wins/Simulations) \n",
      " ♜ ♞ ♝ ♛ ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♙ . . . . . . .\n",
      " ♖ . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "44/65 (Wins/Simulations)\n",
      "0.676923076923077 (Wins/Simulations) \n",
      " ♜ ♞ ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♙ . . . . . . ♛\n",
      " ♖ . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ ♙\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "27/45 (Wins/Simulations)\n",
      "0.6 (Wins/Simulations) \n",
      " ♜ ♞ ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♙ . . . . . . ♛\n",
      " ♖ . ♘ ♗ ♙ . . ♙\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "30/45 (Wins/Simulations)\n",
      "0.6666666666666666 (Wins/Simulations) \n",
      " ♜ ♞ ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . .\n",
      " ♖ . ♘ ♗ ♙ . . ♙\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "40/56 (Wins/Simulations)\n",
      "0.7142857142857143 (Wins/Simulations) \n",
      " ♜ ♞ ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " ♖ . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "26/43 (Wins/Simulations)\n",
      "0.6046511627906976 (Wins/Simulations) \n",
      " ♜ . ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " ♖ . ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . ♘ ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "37/54 (Wins/Simulations)\n",
      "0.6851851851851852 (Wins/Simulations) \n",
      " ♜ . ♝ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " . . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " ♖ . ♘ ♗ ♙ ♘ . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "22/37 (Wins/Simulations)\n",
      "0.5945945945945946 (Wins/Simulations) \n",
      " ♜ . . . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " ♖ . ♘ ♗ ♙ ♘ . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "31/46 (Wins/Simulations)\n",
      "0.6739130434782609 (Wins/Simulations) \n",
      " ♜ . . . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " . ♖ ♘ ♗ ♙ ♘ . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "32/46 (Wins/Simulations)\n",
      "0.6956521739130435 (Wins/Simulations) \n",
      " . . ♜ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . . . . . ♙\n",
      " . ♖ ♘ ♗ ♙ ♘ . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "37/54 (Wins/Simulations)\n",
      "0.6851851851851852 (Wins/Simulations) \n",
      " . . ♜ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . ♞ . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "25/42 (Wins/Simulations)\n",
      "0.5952380952380952 (Wins/Simulations) \n",
      " . . ♜ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . . . . . ♞ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ ♞ . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ ♕ ♔ . . ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "33/48 (Wins/Simulations)\n",
      "0.6875 (Wins/Simulations) \n",
      " . . ♜ . ♚ ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . . . . . ♞ .\n",
      " . ♟ . . ♟ . . ♕\n",
      " ♛ ♞ . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ . ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "34/55 (Wins/Simulations)\n",
      "0.6181818181818182 (Wins/Simulations) \n",
      " . . ♜ ♚ . ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . . . . . ♞ .\n",
      " . ♟ . . ♟ . . ♕\n",
      " ♛ ♞ . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ . ♔ . . ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "26/39 (Wins/Simulations)\n",
      "0.6666666666666666 (Wins/Simulations) \n",
      " . . ♜ ♚ . ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . . . . . ♕ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ ♞ . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♙ ♙ . ♙ ♙ .\n",
      " . . ♗ . ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "32/55 (Wins/Simulations)\n",
      "0.5818181818181818 (Wins/Simulations) \n",
      " . . ♜ ♚ . ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♟ ♟\n",
      " ♝ . . . . . ♕ .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♞ ♙ . ♙ ♙ .\n",
      " . . ♗ . ♔ . . ♖\n",
      "Active Player: white\n",
      "Winner: None\n",
      "22/33 (Wins/Simulations)\n",
      "0.6666666666666666 (Wins/Simulations) \n",
      " . . ♜ ♚ . ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♕ ♟\n",
      " ♝ . . . . . . .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ ♞ ♙ . ♙ ♙ .\n",
      " . . ♗ . ♔ . . ♖\n",
      "Active Player: black\n",
      "Winner: None\n",
      "180/180 (Wins/Simulations)\n",
      "1.0 (Wins/Simulations) \n",
      " . . ♜ ♚ . ♝ . ♜\n",
      " ♟ . ♟ ♟ . ♟ ♕ ♟\n",
      " ♝ . . . . . . .\n",
      " . ♟ . . ♟ . . .\n",
      " ♛ . . ♘ . . . ♙\n",
      " . ♖ ♘ ♗ ♙ . . .\n",
      " . ♙ . ♙ . ♙ ♙ .\n",
      " . . ♗ . ♞ . . ♖\n",
      "Active Player: white\n",
      "Winner: black\n"
     ]
    }
   ],
   "source": [
    "# Reset current state to initial game in case this cell is rerun.\n",
    "mcts.node = mcts.tree\n",
    "\n",
    "# Run MCTS for current node. Find best move and rerun from there up to final game state.\n",
    "while not mcts.node.state.is_final():\n",
    "    mcts.run(n_simulations=1000, verbose=False)\n",
    "    #mcts.node = mcts.node.best_child()\n",
    "    mcts.node = sorted([c for c in mcts.node.children], reverse=True, key=lambda c: c.wins/c.simulations )[0]\n",
    "    print(node_info(mcts.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
